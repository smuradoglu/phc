{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "555b0eb9-3ca7-440d-aeac-56011c8870f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:1200/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fe67ab0c160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "import pandas as pd\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import Dash, dash_table, dcc, html, Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "import base64\n",
    "import datetime\n",
    "import io\n",
    "import plotly.graph_objects as go\n",
    "import copy\n",
    "import plotly.express as px\n",
    "import phonotactic_corpora_analysis1 as phc\n",
    "from legality_principle import LegalitySyllableTokenizer\n",
    "from legality_principle_gbb import LegalitySyllableTokenizer_gbb\n",
    "\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.FLATLY],)\n",
    "\n",
    "# Styling\n",
    "SIDEBAR_STYLE = {\n",
    "    \"position\": \"fixed\",\n",
    "    \"top\": 0,\n",
    "    \"left\": 0,\n",
    "    \"bottom\": 0,\n",
    "    \"width\": \"16rem\",\n",
    "    \"padding\": \"2rem 1rem\",\n",
    "    \"background-color\": \"#f8f9fa\",\n",
    "}\n",
    "\n",
    "CONTENT_STYLE = {\n",
    "    \"margin-left\": \"18rem\",\n",
    "    \"margin-right\": \"1rem\",\n",
    "    \"padding\": \"2rem 1rem\",\n",
    "}\n",
    "\n",
    "BOTTOM_STYLE = {\n",
    "    \"position\": \"fixed\",\n",
    "    \"top\": 600,\n",
    "    \"Bottom\": 0,\n",
    "    \"margin-left\": \"18rem\",\n",
    "    \"margin-right\": \"1rem\",\n",
    "    \"padding\": \"2rem 1rem\",\n",
    "}\n",
    "\n",
    " \n",
    "\n",
    "# Title\n",
    "title = dcc.Markdown(\"Building Blocks Project\",className='bg-primary text-white font-italic', style={\"font-size\": 30})\n",
    "\n",
    "#Components\n",
    "\n",
    "uploader = dcc.Upload(id='upload-data',\n",
    "        children=html.Div(['Drag & Drop or ',html.A('Select Files')]),\n",
    "        style={\n",
    "            'width': '100%',\n",
    "            'height': '60px',\n",
    "            'lineHeight': '60px',\n",
    "            'borderWidth': '1px',\n",
    "            'borderStyle': 'dashed',\n",
    "            'borderRadius': '3px',\n",
    "            'textAlign': 'center',\n",
    "            'margin': '5px'})\n",
    "\n",
    "\n",
    "gf = pd.read_table('lang_operations.tsv')\n",
    "\n",
    "language_options =dcc.RadioItems(id=\"language\",options=gf[\"Language\"].unique(), value=gf[\"Language\"][0],style={'width': '200px'}, )\n",
    "                                 \n",
    "filter_options= dcc.Checklist(id=\"operation\",options=gf[\"Operation\"].unique(),value= [\"None\"],)\n",
    "\n",
    "filter_input =  dcc.Input(id=\"name\",\n",
    "                            value=\"(pa)\",\n",
    "                            className=\"w-100\", )\n",
    "\n",
    "\n",
    "\n",
    "download_button1 = dbc.Button(\"Vowel Position Distribution\", n_clicks=0,id=\"btn_csv1\", style={'font-size': '1.25em'})\n",
    "\n",
    "\n",
    "download_button2 = dbc.Button(\"Root Final Vowel Distribution\", n_clicks=0,id=\"btn_csv2\", style={'font-size': '1.25em'})\n",
    "\n",
    "\n",
    "download_button3 = dbc.Button(\"Vowel Harmony Analysis\", n_clicks=0,id=\"btn_csv3\", style={'font-size': '1.25em'})\n",
    "\n",
    "\n",
    "download_button4 = dbc.Button(\"Place of Articulation Analysis\", n_clicks=0,id=\"btn_csv4\", style={'font-size': '1.25em'})\n",
    "\n",
    "\n",
    "file_type= dcc.Dropdown(id=\"file-type\",\n",
    "                        options=[{\"label\": \"Excel file\", \"value\": \"excel\"},\n",
    "                                {\"label\": \"CSV file\", \"value\": \"csv\"},],\n",
    "                        placeholder=\"Choose download file type\",\n",
    "                                 style={'width': '230px'})\n",
    "vowel_harmony = dcc.Dropdown(['V1V2', 'V2V3', 'V3V4','V4V5', 'V5V6'],value= \"V1V2\")\n",
    "\n",
    "poa_options =dcc.RadioItems(id=\"poa\",options=[' By placement', ' Consonant',' Aggregate'], value= \" Aggregate\",style={'width': '200px'}, )\n",
    "\n",
    "\n",
    "# Card content\n",
    "card_content = [\n",
    "    dbc.CardHeader(\"'Vowel Position Distribution'\"),\n",
    "    dbc.CardBody(\n",
    "        [\n",
    "            html.H5(\"'Vowel Position Distribution'\"),\n",
    "            html.P(\n",
    "                \"Here you might want to add some statics or further information for your dashboard\",\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "]\n",
    "## App layout\n",
    "\n",
    "\n",
    "#Sidebar\n",
    "sidebar = html.Div([dbc.Row([html.H5('Data Settings',style={\"position\": \"fixed\",'margin-top': '10px', 'margin-left': '10px'})],\n",
    "                            style={\"height\": \"2vh\"},),html.Hr(),\n",
    "dbc.Row([html.Div([html.P('File Upload:', style={'margin-top': '8px', 'margin-bottom': '4px'},className='font-weight-bold'),\n",
    "                   uploader,dcc.Store(id='raw-file'),\n",
    "                   html.P('Language:',style={'margin-top': '8px', 'margin-bottom': '4px'},\n",
    "                           className='font-weight-bold'),language_options,html.Br(),\n",
    "                    html.P('Corpus Filter Options:',\n",
    "                           style={'margin-top': '86x', 'margin-bottom': '4px'},\n",
    "                           className='font-weight-bold'), filter_options, html.Br(),'String removal Filter:',\n",
    "                           filter_input, dcc.Store(id='table-master'),html.Br(),\n",
    "                   dbc.Row([html.H5('Analysis Settings',style={'margin-top': '6px', 'margin-left': '10px'})],\n",
    "                            style={\"height\": \"2vh\"}),\n",
    "                    html.Hr(), html.P('Vowel Harmony Combinations:',\n",
    "                           style={'margin-top': '16px', 'margin-bottom': '4px'},\n",
    "                           className='font-weight-bold'), vowel_harmony,html.P('P.O.A. Combinations:',\n",
    "                           style={'margin-top': '16px', 'margin-bottom': '4px'},\n",
    "                           className='font-weight-bold'),poa_options])])],\n",
    "                   style=SIDEBAR_STYLE,)\n",
    "\n",
    "# Content\n",
    "\n",
    "        \n",
    "\n",
    "top_content = html.Div([\n",
    "    dcc.Tabs([\n",
    "        dcc.Tab(label='Tabular View', children=[dash_table.DataTable(id='output-data-upload', export_format=\"csv\",filter_action=\"native\", \n",
    "        row_deletable=True,sort_action=\"native\",sort_mode=\"multi\",fill_width=False,editable=True,column_selectable=\"single\", page_size= 10,\n",
    "    style_data={'whiteSpace': 'normal','height': 'auto','lineHeight': '10px'})\n",
    "\n",
    "        ]),\n",
    "        dcc.Tab(label='Bar Plot', children=[html.Div(dcc.Graph(\n",
    "            id='table-paging-with-graph-container',)),\n",
    "\n",
    "\n",
    "\n",
    "                                            \n",
    " ]),\n",
    "    ])\n",
    "],style = CONTENT_STYLE)\n",
    "\n",
    "\n",
    "\n",
    "bottom_content  = html.Div([ \n",
    "dbc.Row([dbc.Col([ dbc.Row([dbc.Col([dbc.Card(html.Div([download_button1,html.Br(),html.Br(),\n",
    "            html.P(\"Distribution of vowels per syllable positions\",),html.Div([html.Hr(),\n",
    "        dcc.Download(id=\"download-vtable\"),dash_table.DataTable(id='vtable_data',export_format=\"csv\",filter_action=\"native\", \n",
    "        row_deletable=True,sort_action=\"native\",sort_mode=\"multi\",fill_width=False,editable=True,column_selectable=\"single\", page_size= 8,style_data={'whiteSpace': 'normal','height': 'auto','lineHeight': '10px'},),])],\n",
    "        className=\"text-center text-nowrap my-2 p-2\",), color=\"light\")]),\n",
    "        dbc.Col([dbc.Card(html.Div([download_button2,html.Br(),html.Br(),html.P(\"Distribution of vowels in root final position\",),\n",
    "                                    html.Div([html.Hr(),\n",
    "        dash_table.DataTable(id='rtable_data',export_format=\"csv\",filter_action=\"native\", \n",
    "        row_deletable=True,sort_action=\"native\",sort_mode=\"multi\",fill_width=False,editable=True,column_selectable=\"single\", page_size= 8,style_data={'whiteSpace': 'normal','height': 'auto','lineHeight': '10px'},),])],\n",
    "        className=\"text-center text-nowrap my-2 p-2\",), color=\"light\")]),\n",
    "                            dbc.Col([dbc.Card(html.Div([download_button3,html.Br(),html.Br(),html.P(\"Distribution of vowel transition from one syllable to another\",),\n",
    "                                                        html.Div([html.Hr(),\n",
    "        dash_table.DataTable(id='vhartable_data',export_format=\"csv\",filter_action=\"native\", \n",
    "        row_deletable=True,sort_action=\"native\",sort_mode=\"multi\",fill_width=False,editable=True,column_selectable=\"single\", page_size= 8,style_data={'whiteSpace': 'normal','height': 'auto','lineHeight': '10px'},),])],\n",
    "        className=\"text-center text-nowrap my-2 p-2\",), color=\"light\")]),\n",
    "                            dbc.Col([dbc.Card(html.Div([download_button4,html.Br(),html.Br(),html.P(\"Distribution of place of articulation (P.O.A.) following a vowel\",),\n",
    "                                                        html.Div([html.Hr(),\n",
    "        dash_table.DataTable(id='poatable_data',export_format=\"csv\",filter_action=\"native\", \n",
    "        row_deletable=True,sort_action=\"native\",sort_mode=\"multi\",fill_width=False,editable=True,column_selectable=\"single\", page_size= 8,style_data={'whiteSpace': 'normal','height': 'auto','lineHeight': '10px'},),])],\n",
    "        className=\"text-center text-nowrap my-2 p-2\",), color=\"light\")]),\n",
    "                            \n",
    "                            ]\n",
    "                        )\n",
    "                    ],\n",
    "                    width=15,\n",
    "                    style={\"margin\": \"auto\"},\n",
    "                ),\n",
    "            ])\n",
    "                           \n",
    "                           ], style=BOTTOM_STYLE)\n",
    "\n",
    "\n",
    "# App Layout\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "        dbc.Row([dbc.Col([title], style={\"text-align\": \"center\", \"margin\": \"auto\"})]),\n",
    "        sidebar,\n",
    "        top_content, bottom_content\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "## Callbacks\n",
    "\n",
    "\n",
    "@app.callback(Output('raw-file', 'data'),\n",
    "              Input('upload-data', 'contents'),\n",
    "              State('upload-data', 'filename'))\n",
    "def update_output(contents, list_of_names,):\n",
    "    if contents is None:\n",
    "        raise PreventUpdate\n",
    "    content_type, content_string = contents.split(',')\n",
    "    decoded = base64.b64decode(content_string)\n",
    "    df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))\n",
    "    return df.to_json(date_format='iso', orient='split')\n",
    "\n",
    "@app.callback(\n",
    "    Output('output-data-upload','data'),\n",
    "    Output('output-data-upload', 'columns'),\n",
    "    Output('table-master','data'),\n",
    "    Input('raw-file','data'),\n",
    "    Input(component_id=filter_options, component_property=\"value\"),\n",
    "    Input(component_id=filter_input, component_property=\"value\"),\n",
    "    Input(component_id=language_options,component_property=\"value\"),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def update_table(frame, check_value, filt_str, lang_value):\n",
    "    df = pd.read_json(frame, orient='split')\n",
    "    head = df['headword'].tolist()\n",
    "    head1 = df['headword'].tolist()\n",
    "    tag = df['pos'].tolist()\n",
    "    mean = df['gloss'].tolist()\n",
    "    if 'None' in check_value:\n",
    "        head1=head1\n",
    "    if 'Verb Segmentation' in check_value:\n",
    "        ptj_vseg = phc.lightverb_space(head1)\n",
    "        ptj_incho= phc.ptj_incho_segment(ptj_vseg,tag)\n",
    "        ptj_vseg1 = phc.ptj_verb_segment(ptj_incho,tag)\n",
    "        head = phc.ptj_augment_segment(ptj_vseg1,tag)\n",
    "    if 'Verbal Morphology' in check_value and 'Pitjantjatjara' in lang_value:\n",
    "        head1 = phc.ptj_verb(head,tag)\n",
    "    if 'Verbal Morphology' in check_value and 'Warlpiri' in lang_value:\n",
    "        head1 = phc.wbp_verb(head1,tag)\n",
    "    if 'String removal' in check_value:\n",
    "        head1 = phc.remove_items(head1,str(filt_str))\n",
    "    seg1, seg2 = phc.segment(head)\n",
    "    if 'Verb compound' in check_value:\n",
    "        head1 = phc.vcompound(head1,seg1,seg2)\n",
    "    if 'Reduplication' in check_value:\n",
    "        head1= phc.redup(head1,seg1,seg2)\n",
    "    if 'Light Verb' in check_value:\n",
    "        ptj_light= phc.ptj_verb_comp(head1)\n",
    "        head1=phc.ptj_verb(ptj_light,tag)\n",
    "    if lang_value == 'Warumungu':\n",
    "        vow, vow_count = phc.vowel_count(head1)\n",
    "        ipa = phc.orth2ipa('wrm',head1)\n",
    "        syll_ipa = phc.orth2ipa('wrm',vow_count)\n",
    "        syll_clean = phc.remove_items(syll_ipa, '-')\n",
    "        syll, syll_u= phc.syllable(syll_clean)\n",
    "    if lang_value == 'Kaytetye':\n",
    "        ipa =  df['IPA'].tolist()\n",
    "        vow = phc.gbb_vowel_count(ipa)\n",
    "        syll, syll_u= phc.syllable(ipa)\n",
    "        syll_clean = ipa\n",
    "    if lang_value == 'Pitjantjatjara':\n",
    "        vow, vow_count = phc.vowel_count(head1)\n",
    "        ipa = phc.orth2ipa('ptj',head1)\n",
    "        syll_ipa = phc.orth2ipa('ptj',vow_count)\n",
    "        syll_clean = phc.remove_items(syll_ipa, '-')\n",
    "        syll, syll_u= phc.syllable(syll_clean)\n",
    "    if lang_value == 'Warlpiri':\n",
    "        vow, vow_count = phc.vowel_count(head1)\n",
    "        ipa = phc.orth2ipa('wbp',head1)\n",
    "        syll_ipa = phc.orth2ipa('wbp',vow_count)  \n",
    "        syll_clean = phc.remove_items(syll_ipa, '-')\n",
    "        syll, syll_u= phc.syllable(syll_clean)\n",
    "\n",
    "    if 'Manual Syllables' in check_value:\n",
    "        sylla = df['manual_syllable'].tolist()\n",
    "        dff =phc.prestichframe(head,ipa,syll_clean,tag, mean, vow, sylla, seg1,seg2)        \n",
    "    else:\n",
    "        dff =phc.prestichframe(head,ipa,syll_clean,tag, mean, vow, syll, seg1,seg2)\n",
    "    if 'Independent Word' in check_value:\n",
    "        dff =phc.stichframe(head,ipa,syll_clean,tag, mean, vow, syll, seg1,seg2)\n",
    "    if 'Drop duplicates' in check_value:\n",
    "        dff= phc.drop_dup(dff)\n",
    "\n",
    "    if 'Drop English Loans' in check_value:\n",
    "        dff = phc.drop_Eng(dff)\n",
    "\n",
    "    return dff.to_dict('records'), [{\"name\": i, \"id\": i, \"deletable\": True, \"selectable\": True} for i in dff.columns], dff.to_json(date_format='iso', orient='split',force_ascii=False)\n",
    "\n",
    "@app.callback(\n",
    "    Output('output-data-upload', 'style_data_conditional'),\n",
    "    Input('output-data-upload', 'selected_columns'),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def update_styles(selected_columns):\n",
    "    return [{\n",
    "        'if': { 'column_id': i },\n",
    "        'background_color': '#D2F3FF'\n",
    "    } for i in selected_columns]\n",
    "    \n",
    "@app.callback(\n",
    "    Output('table-paging-with-graph-container', \"figure\"),\n",
    "    Input('output-data-upload','derived_virtual_data'),\n",
    "    Input('output-data-upload', \"derived_virtual_selected_rows\"),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "    \n",
    "def update_graph(rows,derived_virtual_selected_rows):\n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "\n",
    "    dff = df if rows is None else pd.DataFrame(rows)\n",
    "    colors = ['#7FDBFF' if i in derived_virtual_selected_rows else '#0074D9'\n",
    "              for i in range(len(dff))]\n",
    "    if dff.empty:\n",
    "        fig = px.histogram(dff, x=[])\n",
    "        return fig\n",
    "    else:\n",
    "        fig = px.histogram(dff, x=\"syllable_count\",text_auto =True)\n",
    "        fig.update_layout(bargap=0.1, font=dict(family=\"Courier New, monospace\", size=14))\n",
    "        return fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('vtable_data','data'),\n",
    "    Output('vtable_data', 'columns'),\n",
    "    Input('output-data-upload','derived_virtual_data'),\n",
    "    Input('output-data-upload', \"derived_virtual_selected_rows\"),\n",
    "    Input(component_id=language_options,component_property=\"value\"),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def vowel_position(rows,derived_virtual_selected_rows,lang_value):\n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "\n",
    "    dff = df if rows is None else pd.DataFrame(rows)\n",
    "    colors = ['#7FDBFF' if i in derived_virtual_selected_rows else '#0074D9'\n",
    "              for i in range(len(dff))]\n",
    "\n",
    "    if dff.empty:\n",
    "        return dff.to_dict('records'), [{\"name\": i, \"id\": i, \"deletable\": False, \"selectable\": True} for i in dff.columns]\n",
    "    else: \n",
    "        syllables, syllable_len = phc.count_syllables(dff)\n",
    "        y =phc.count_syllable_position(syllables, syllable_len)\n",
    "        if 'Kaytetye' in lang_value: \n",
    "            vowel_frame = phc.gbb_vowel_distribution(y)\n",
    "        else:\n",
    "            vowel_frame = phc.vowel_distribution(y)\n",
    "        return vowel_frame.to_dict('records'), [{\"name\": i, \"id\": i, \"deletable\": False, \"selectable\": True} for i in vowel_frame.columns]\n",
    "\n",
    "@app.callback(\n",
    "    Output('rtable_data','data'),\n",
    "    Output('rtable_data', 'columns'),\n",
    "    Input('output-data-upload','derived_virtual_data'),\n",
    "    Input('output-data-upload', \"derived_virtual_selected_rows\"),\n",
    "    Input(component_id=language_options,component_property=\"value\"),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def rfinal_vowel(rows,derived_virtual_selected_rows,lang_value):\n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "\n",
    "    dff = df if rows is None else pd.DataFrame(rows)\n",
    "    colors = ['#7FDBFF' if i in derived_virtual_selected_rows else '#0074D9'\n",
    "              for i in range(len(dff))]\n",
    "    if dff.empty:\n",
    "        return dff.to_dict('records'), [{\"name\": i, \"id\": i, \"deletable\": False, \"selectable\": True} for i in dff.columns]\n",
    "    else: \n",
    "        syllables, syllable_len = phc.count_syllables(dff)\n",
    "        word = phc.word_length(syllables, syllable_len)\n",
    "        if 'Kaytetye' in lang_value: \n",
    "            root_final_vowel = phc.gbb_count_vowels(word)\n",
    "        else:\n",
    "            root_final_vowel = phc.count_vowels(word)\n",
    "        return root_final_vowel.to_dict('records'),[{\"name\": i, \"id\": i, \"deletable\": False, \"selectable\": True} for i in root_final_vowel.columns]\n",
    "\n",
    "@app.callback(\n",
    "    Output('vhartable_data','data'),\n",
    "    Output('vhartable_data', 'columns'),\n",
    "    Input('output-data-upload','derived_virtual_data'),\n",
    "    Input('output-data-upload', \"derived_virtual_selected_rows\"),\n",
    "    Input(vowel_harmony,'value'),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def vowel_harm(rows,derived_virtual_selected_rows,vspec):\n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "\n",
    "    dff = df if rows is None else pd.DataFrame(rows)\n",
    "    colors = ['#7FDBFF' if i in derived_virtual_selected_rows else '#0074D9'\n",
    "              for i in range(len(dff))]\n",
    "    if dff.empty:\n",
    "        return dff.to_dict('records'), [{\"name\": i, \"id\": i, \"deletable\": False, \"selectable\": True} for i in dff.columns]\n",
    "    else:\n",
    "        syllables, syllable_len = phc.count_syllables(dff)\n",
    "        syll = phc.clean_syllables(dff)\n",
    "        syl_matrix = pd.DataFrame(syll, columns=['sy1'])\n",
    "        syl_matrix[['sy1', 'sy2']] = syl_matrix['sy1'].str.split(',', 1, expand=True).fillna('')  \n",
    "        if max(syllable_len) == 3:\n",
    "            syl_matrix[['sy2', 'sy3']] = syl_matrix['sy2'].str.split(',', 1, expand=True).fillna('')\n",
    "        if max(syllable_len) == 4:\n",
    "            syl_matrix[['sy2', 'sy3']] = syl_matrix['sy2'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy3', 'sy4']] = syl_matrix['sy3'].str.split(',', 1, expand=True).fillna('')\n",
    "        if max(syllable_len) == 5:\n",
    "            syl_matrix[['sy2', 'sy3']] = syl_matrix['sy2'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy3', 'sy4']] = syl_matrix['sy3'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy4', 'sy5']] = syl_matrix['sy4'].str.split(',', 1, expand=True).fillna('')\n",
    "        if max(syllable_len) == 6:\n",
    "            syl_matrix[['sy2', 'sy3']] = syl_matrix['sy2'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy3', 'sy4']] = syl_matrix['sy3'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy4', 'sy5']] = syl_matrix['sy4'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy5', 'sy6']] = syl_matrix['sy5'].str.split(',', 1, expand=True).fillna('')\n",
    "        if max(syllable_len) == 7:\n",
    "            syl_matrix[['sy2', 'sy3']] = syl_matrix['sy2'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy3', 'sy4']] = syl_matrix['sy3'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy4', 'sy5']] = syl_matrix['sy4'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy5', 'sy6']] = syl_matrix['sy5'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy6', 'sy7']] = syl_matrix['sy6'].str.split(',', 1, expand=True).fillna('')\n",
    "        if max(syllable_len) == 8:\n",
    "            syl_matrix[['sy2', 'sy3']] = syl_matrix['sy2'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy3', 'sy4']] = syl_matrix['sy3'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy4', 'sy5']] = syl_matrix['sy4'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy5', 'sy6']] = syl_matrix['sy5'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy6', 'sy7']] = syl_matrix['sy6'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy7', 'sy8']] = syl_matrix['sy7'].str.split(',', 1, expand=True).fillna('')\n",
    "        if max(syllable_len) == 9:\n",
    "            syl_matrix[['sy2', 'sy3']] = syl_matrix['sy2'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy3', 'sy4']] = syl_matrix['sy3'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy4', 'sy5']] = syl_matrix['sy4'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy5', 'sy6']] = syl_matrix['sy5'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy6', 'sy7']] = syl_matrix['sy6'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy7', 'sy8']] = syl_matrix['sy7'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy8', 'sy9']] = syl_matrix['sy8'].str.split(',', 1, expand=True).fillna('')\n",
    "        if max(syllable_len) == 10:\n",
    "            syl_matrix[['sy2', 'sy3']] = syl_matrix['sy2'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy3', 'sy4']] = syl_matrix['sy3'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy4', 'sy5']] = syl_matrix['sy4'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy5', 'sy6']] = syl_matrix['sy5'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy6', 'sy7']] = syl_matrix['sy6'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy7', 'sy8']] = syl_matrix['sy7'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy8', 'sy9']] = syl_matrix['sy8'].str.split(',', 1, expand=True).fillna('')\n",
    "            syl_matrix[['sy9', 'sy10']] = syl_matrix['sy9'].str.split(',', 1, expand=True).fillna('')\n",
    "        vowel_matrix=phc.vowel_matrix(syl_matrix)\n",
    "        df_out = vowel_matrix.groupby(['sy1', 'sy2']).size().reset_index(name='count')\n",
    "        if vspec == 'V2V3':\n",
    "            df_out = vowel_matrix.groupby(['sy2', 'sy3']).size().reset_index(name='count')\n",
    "        if vspec =='V3V4':\n",
    "            df_out = vowel_matrix.groupby(['sy3', 'sy4']).size().reset_index(name='count')\n",
    "        if vspec == 'V4V5':\n",
    "            df_out = vowel_matrix.groupby(['sy4', 'sy5']).size().reset_index(name='count')\n",
    "        if vspec == 'V5V6':\n",
    "            df_out = vowel_matrix.groupby(['sy5', 'sy6']).size().reset_index(name='count')\n",
    "        return df_out.to_dict('records'),[{\"name\": i, \"id\": i, \"deletable\": False, \"selectable\": True} for i in df_out.columns]\n",
    "\n",
    "@app.callback(\n",
    "    Output('poatable_data','data'),\n",
    "    Output('poatable_data', 'columns'),\n",
    "    Input('output-data-upload','derived_virtual_data'),\n",
    "    Input('output-data-upload', \"derived_virtual_selected_rows\"),\n",
    "    Input(component_id=language_options,component_property=\"value\"),\n",
    "    Input(poa_options,'value'),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "        \n",
    "def poa_dist(rows,derived_virtual_selected_rows, lang,poa_filter):\n",
    "    if derived_virtual_selected_rows is None:\n",
    "        derived_virtual_selected_rows = []\n",
    "\n",
    "    dff = df if rows is None else pd.DataFrame(rows)\n",
    "    colors = ['#7FDBFF' if i in derived_virtual_selected_rows else '#0074D9'\n",
    "              for i in range(len(dff))]\n",
    "    if dff.empty:\n",
    "        return dff.to_dict('records'), [{\"name\": i, \"id\": i, \"deletable\": False, \"selectable\": True} for i in dff.columns]\n",
    "    else:\n",
    "        syll_clean= dff['OS'].tolist()\n",
    "        word_tmp = phc.word_template(lang,syll_clean)\n",
    "        onset, coda = phc.VC_clusters(syll_clean,word_tmp)\n",
    "        onset_poa =phc.poa_labeller(onset)\n",
    "        coda_poa =phc.poa_labeller(coda)\n",
    "        onset_lab = list(len(onset)*['onset'])\n",
    "        coda_lab = list(len(coda)*['coda'])\n",
    "        onsetV, onsetC = phc.VC_spliter(onset)\n",
    "        codaV, codaC = phc.VC_spliter(coda)\n",
    "        bf = pd.DataFrame(list(zip(onset,onsetV,onsetC,onset_lab, onset_poa)),columns=['VC','V','C','placement','poa'])\n",
    "        gf = pd.DataFrame(list(zip(coda,codaV,codaC,coda_lab, coda_poa)),columns=['VC','V','C','placement','poa'])\n",
    "        ff = pd.concat([bf,gf])\n",
    "        if poa_filter == ' Aggregate':\n",
    "            poatab= ff.groupby(['V', 'poa']).size().reset_index(name='count')\n",
    "        if poa_filter == ' By placement':\n",
    "            poatab= ff.groupby(['V', 'poa', 'placement']).size().reset_index(name='count')\n",
    "        if poa_filter == ' Consonant':\n",
    "            poatab= ff.groupby(['V', 'C']).size().reset_index(name='count')\n",
    "        return poatab.to_dict('records'),[{\"name\": i, \"id\": i, \"deletable\": False, \"selectable\": True} for i in poatab.columns]\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"language\", \"options\"),\n",
    "    Input(\"operation\", \"value\"),\n",
    ")\n",
    "def chained_callback_language(operation):\n",
    "    gff = copy.deepcopy(gf)\n",
    "    if operation is not None:\n",
    "        gff = gff.query(\"Operation == @operation\")\n",
    "    return sorted(gff[\"Language\"].unique())\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"operation\", \"options\"),\n",
    "    Input(\"language\", \"value\"),\n",
    ")\n",
    "def chained_callback_operation(language):\n",
    "    gff = copy.deepcopy(gf)\n",
    "    if language is not None:\n",
    "        gff = gff.query(\"Language == @language\")\n",
    "    return sorted(gff[\"Operation\"].unique())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True, external ='tab', port =1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f401e612-897e-4fe0-b36b-30cc95bc64b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting print-versions\n",
      "  Downloading print_versions-0.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading print_versions-0.1.0-py3-none-any.whl (2.8 kB)\n",
      "\u001b[33mWARNING: Error parsing dependencies of gym: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    opencv-python (>=3.) ; extra == 'all'\n",
      "                  ~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Error parsing dependencies of omegaconf: .* suffix can only be used with `==` or `!=` operators\n",
      "    PyYAML (>=5.1.*)\n",
      "            ~~~~~~^\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: print-versions\n",
      "Successfully installed print-versions-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install print-versions # works for python >= 3.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ee6be0-1eba-4881-a67d-21ea6f1bf33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip==24.2\n",
      "numpy==1.24.3\n",
      "pandas==1.5.3\n",
      "dash==2.18.1\n",
      "dash_bootstrap_components==1.6.0\n",
      "dash.dash_table==5.2.12\n",
      "dash.dcc==2.14.2\n",
      "dash.html==2.0.19\n"
     ]
    }
   ],
   "source": [
    "from print_versions import print_versions\n",
    "\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "print_versions(globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbde0fc-a188-4c54-b3b5-55d26f8fdcda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
